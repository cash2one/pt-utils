##################################################
#
#  demo module.conf
#  请修改 test_machine/module_name/module_owner/mail_list/gsm_list
#         
###################################################

[module]
test_machine    =   cq01-2012h1-3-uptest3.vm.baidu.com

module_name     =   demo-project
module_owner    =   pengtao

local_work_path =  /home/work/%module_owner/%module_name
hdfs_work_path  =  /ps/ubs/%module_owner/%module_name


[required]

hadoop_home     =    %hadoop_home_stoff

local_log_path      =   %local_work_path/log/
local_logbak_path   =   %local_work_path/logbak/
local_flag_path     =   %local_work_path/flag/

#required: mail_list gsm_list
mail_list               =   pengtao@baidu.com
gsm_list                =   13671016422


[hdfs_log_path]

core_path               =   %hdfs_work_path/debug/

## 日志路径 （stoff）
# /log/20682/accesslog_to_stoff/20120807/0000/szwg-rank-hdfs.dmop/17/tc-se-click0-3.17.00.log.lzma
accesslog_hadoop_root   =   /log/20682/accesslog_to_stoff/
# /log/20682/bws_access/20120814/0000/szwg-rank-hdfs.dmop/22/bws_access_log.jx-www-pr31.jx.baidu.com.2012081422.lzma
bwslog_hadoop_path      =   /log/20682/bws_access/
# /log/20682/mergelog_v1/20120701/0000/szwg-rank-hdfs.dmop/part-02999.gz
mergelogv1_hadoop_root  =   /log/20682/mergelog_v1/
# /log/20682/mergelog_v2_daily_to_stoff/20120701/0000/szwg-rank-hdfs.dmop/part-00000-A
mergelogv2_hadoop_root  =   /log/20682/mergelog_v2_daily_to_stoff/
# /log/20682/newcookiesort/20120801/0000/szwg-rank-hdfs.dmop/part-00284.lzma
newcookiesort_hadoop_root =   /log/20682/newcookiesort/
# /log/20682/ps_bz_log_dump/20120824/0100/szwg-rank-hdfs.dmop/10/cq01-ps-wwwui14-t10.cq01/ui/url.log
uilog_hadoop_root       =  /log/20682/ps_bz_log_dump/
# /log/20682/click_adjust_new_to_stoff/20121013/0000/merge_round2/part-00799
clickadjust_round2_hadoop_root = /log/20682/click_adjust_new_to_stoff/
# /log/2295/holmes_pre_session_off_for_ps_ubs/20121013/0000/szwg-ecomon-hdfs.dmop/2300/session.2012101323-tc-hm-pre00.tc
holmess_pre_session_hadoop_root = /log/2295/holmes_pre_session_off_for_ps_ubs/
#  /log/20682/sobar_urldata_ston_to_stoff/20121017/0000/szwg-ston-hdfs.dmop/0415/yf-p2p-web07.yf01.baidu.com_20121017041500.log
sobar_urldata_hadoop_root = /log/20682/sobar_urldata_ston_to_stoff/
# ston: /app/ns/lsp/output/ubs/logdata_sobar_session_foreproc/20121023/0000/part-00399
sobar_logdata_session_hadoop_root = /app/ns/lsp/output/ubs/logdata_sobar_session_foreproc/

hdfs_detailnewquerysort =   /log/20682/detailnewquerysort/@date@/0000/szwg-*-hdfs.dmop/part-*

[hadoop_job_setting]

hadoop_home_stoff =  /home/work/hadoop-client-stoff/hadoop
hadoop_home_ston  =  /home/work/hadoop-client-ston/hadoop
hadoop_home_rank  =  /home/work/hadoop-client-rank/hadoop


# retry times and interval for mrjob and master
retry_times             =   0
retry_interval          =   60
# retry times and interval for file checking
check_retry_times       =   3
check_retry_interval    =   60
# hadoop arguments
stream.memory.limit         =   800
mapred.task.timeout         =   600000
mapred.job.priority         =   HIGH

## common files
## 所有job都会添加的文件，一般不指定
# file                =   %local_work_path/bwslog_get_360_cookie_M.py
#                         %local_work_path/bwslog_get_360_cookie_R.py

python_tar_gz   =  -cacheArchive  /ps/ubs/pengtao/cacheArchive/python2.7.tar.gz#python2.7
python_bin      =   ./python2.7/bin/python


## invoke frame function (export argument to environ)
# export_environ  =   @func export_environ: accesslog_hadoop_path .value


# error_rank_receiver     =   q(pengtao@baidu.com)
# error_sos_receiver      =   q(pengtao@baidu.com)
# phone_rank_receiver     =   q(pengtao@baidu.com)
# phone_sos_receiver      =   q(pengtao@baidu.com)







